{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Prediction and Particle Swarm Optimization\n",
    "\n",
    "This notebook predicts house prices using multiple regressors and optimizes their ensemble weights using Particle Swarm Optimization (PSO).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess the Data\n",
    "We load the training and test datasets, preprocess them to handle missing values and categorical variables, and scale the features for better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyswarm import pso\n",
    "\n",
    "# Load training data\n",
    "data_train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Separate features and target for training\n",
    "X_train = data_train.drop([\"SalePrice\", \"Id\"], axis=1)\n",
    "y_train = data_train[\"SalePrice\"]\n",
    "\n",
    "# Handle categorical features in training data\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "# Fill missing values in training data\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "\n",
    "# Load test data\n",
    "data_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# Keep track of IDs in test data for output\n",
    "test_ids = data_test[\"Id\"]\n",
    "\n",
    "# Drop ID column in test data\n",
    "X_test = data_test.drop([\"Id\"], axis=1)\n",
    "\n",
    "# Handle categorical features in test data\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Align test data with training data (add missing columns)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Fill missing values in test data\n",
    "X_test = X_test.fillna(X_train.median())\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train Multiple Regressors\n",
    "We train three regression models: Random Forest, Support Vector Regression (SVR), and K-Nearest Neighbors (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE for RandomForest: 120823814.9010809\n",
      "Training MSE for SVR: 6626763595.51494\n",
      "Training MSE for KNeighbors: 1279290126.952502\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_estimators=100),\n",
    "    \"SVR\": SVR(kernel='rbf', C=10, gamma=0.1),\n",
    "    \"KNeighbors\": KNeighborsRegressor(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Train and store predictions\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions[name] = model.predict(X_test)\n",
    "\n",
    "# Replace NaN values in predictions if necessary\n",
    "for name in predictions:\n",
    "    predictions[name] = np.nan_to_num(predictions[name])\n",
    "\n",
    "# Generate training predictions for PSO\n",
    "train_predictions = {}\n",
    "for name, model in models.items():\n",
    "    train_predictions[name] = model.predict(X_train)\n",
    "\n",
    "# Display individual model performance on training data\n",
    "for name, model in models.items():\n",
    "    train_predictions_train = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, train_predictions_train)\n",
    "    print(f\"Training MSE for {name}: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Save Unoptimized Predictions\n",
    "Before optimizing ensemble weights, compute and save unoptimized mean predictions for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoptimized predictions saved as 'data/submission2.csv'\n"
     ]
    }
   ],
   "source": [
    "# Compute mean ensemble prediction without optimization\n",
    "unoptimized_ensemble = sum(predictions[name] for name in models) / len(models)\n",
    "\n",
    "# Save unoptimized predictions to submission2.csv\n",
    "submission2 = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": unoptimized_ensemble})\n",
    "submission2.to_csv(\"data/submission2.csv\", index=False)\n",
    "print(\"Unoptimized predictions saved as 'data/submission2.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define the PSO Objective Function\n",
    "The objective function minimizes the Mean Squared Error (MSE) by optimizing weights for the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(weights):\n",
    "    weights = np.array(weights)\n",
    "    if weights.sum() == 0:\n",
    "        return 1e10\n",
    "    \n",
    "    weights = weights / weights.sum()  # Normalize weights\n",
    "    \n",
    "    # Compute ensemble predictions on training data\n",
    "    ensemble_prediction = sum(weights[i] * train_predictions[name] for i, name in enumerate(models))\n",
    "    \n",
    "    # Replace NaN values in the predictions\n",
    "    ensemble_prediction = np.nan_to_num(ensemble_prediction)\n",
    "    \n",
    "    # Ensure that the prediction length matches y_train\n",
    "    if len(ensemble_prediction) != len(y_train):\n",
    "        raise ValueError(f\"Prediction length mismatch: {len(ensemble_prediction)} != {len(y_train)}\")\n",
    "    \n",
    "    return mean_squared_error(y_train, ensemble_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Optimize Weights with PSO\n",
    "Use the PSO algorithm to find the optimal weights for combining the predictions of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 200\n",
      "Weight for RandomForest: 1.0\n",
      "Weight for SVR: 0.0\n",
      "Weight for KNeighbors: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Define bounds for weights\n",
    "lb = [0] * len(models)\n",
    "ub = [1] * len(models)\n",
    "\n",
    "# Run PSO\n",
    "optimal_weights, _ = pso(objective_function, lb, ub, swarmsize=100, maxiter=200)\n",
    "\n",
    "# Normalize optimal weights\n",
    "optimal_weights = optimal_weights / sum(optimal_weights)\n",
    "\n",
    "# Display results\n",
    "for i, name in enumerate(models):\n",
    "    print(f\"Weight for {name}: {optimal_weights[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Final Ensemble\n",
    "Combine model predictions using the optimized weights and save the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized predictions saved as 'data/submission.csv'\n",
      "Unoptimized predictions saved as 'data/submission2.csv'\n"
     ]
    }
   ],
   "source": [
    "# Compute final ensemble prediction\n",
    "optimized_ensemble = sum(optimal_weights[i] * predictions[name] for i, name in enumerate(models))\n",
    "\n",
    "# Save optimized predictions to submission.csv\n",
    "submission = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": optimized_ensemble})\n",
    "submission.to_csv(\"data/submission.csv\", index=False)\n",
    "print(\"Optimized predictions saved as 'data/submission.csv'\")\n",
    "\n",
    "# Save both submissions\n",
    "submission2 = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": unoptimized_ensemble})\n",
    "submission2.to_csv(\"data/submission2.csv\", index=False)\n",
    "print(\"Unoptimized predictions saved as 'data/submission2.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
